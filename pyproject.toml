# BLACK
[tool.black]
target-version = ["py311"]
line-length = 120
include = '\.pyi?$'
extend-exclude = '''
/(
  src/notebooks
  #| src/notebooks
)/
'''

# ISORT
[tool.isort]
py_version = 311
line_length = 120
profile = "black"
atomic = true
lines_after_imports = 2
combine_as_imports = true
force_alphabetical_sort_within_sections = true
treat_comments_as_code = ["# COMMAND ----------", "# DBTITLE 1"]
src_paths = ["src"]

# MYPY
[tool.mypy]
python_version = "3.11"
warn_return_any = true
warn_unused_configs = true
ignore_missing_imports = true
follow_imports = "silent"
namespace_packages = false
disable_error_code = ["import-untyped"]
exclude = ["src/lib/job.py"]

# PYLINT
[tool.pylint.main]
py-version = "3.11"
source-roots = ["."]
load-plugins = [
    "pylint.extensions.bad_builtin",
    "pylint.extensions.check_elif",
    "pylint.extensions.comparison_placement",
    "pylint.extensions.dict_init_mutate",
    "pylint.extensions.docstyle",
    "pylint.extensions.empty_comment",
    "pylint.extensions.for_any_all",
    "pylint.extensions.mccabe",
    "pylint.extensions.no_self_use",
    "pylint.extensions.private_import",
    "pylint.extensions.redefined_loop_name",
    "pylint.extensions.redefined_variable_type",
    "pylint.extensions.typing",
]

[tool.pylint.logging]
logging-format-style = "new"

[tool.pylint.format]
max-line-length = 120
expected-line-ending-format = "LF"

[tool.pylint.messages_control]
disable = """
    wrong-import-position,
    import-outside-toplevel,
    docstring-first-line-empty,
    fixme,
    no-name-in-module,
    too-few-public-methods,
    logging-fstring-interpolation,
    too-many-instance-attributes,
"""
# missing-class-docstring,
# missing-module-docstring,
# duplicate-code,

# PYTEST
[tool.pytest.ini_options]
pythonpath = ["."]
spark_options = ["spark.sql.session.timeZone: UTC"]

# POETRY
[tool.poetry]
package-mode = false  # use only for dependency management
name = "databricks_pipelines"

# VERSIONS
[tool.poetry.dependencies]
python = "3.12.*"  # Python 3.12 is used for Databricks runtime 16.1 (see Databricks Runtime release notes)
databricks-sdk = "*"
python-dotenv = "*"

[tool.poetry.group.dev.dependencies]
pyspark = "3.5.*"
delta-spark = "3.2.*"  # Spark compatibility: https://docs.delta.io/latest/releases.html#compatibility-with-apache-spark
databricks-dlt = "*"  # Python stub for Delta Live Tables
# linters
black = "*"
isort = "*"
mypy = "*"
pylint = "*"
# testing
pytest = "*"
pytest-spark = "*"
# other
colorama = "*"
