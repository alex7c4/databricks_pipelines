# BLACK
[tool.black]
target-version = ["py312"]
line-length = 120
include = '\.pyi?$'
extend-exclude = '''
/(
  src/notebooks
  #| src/notebooks
)/
'''

# ISORT
[tool.isort]
py_version = 312
line_length = 120
profile = "black"
atomic = true
lines_after_imports = 2
combine_as_imports = true
force_alphabetical_sort_within_sections = true
treat_comments_as_code = ["# COMMAND ----------", "# DBTITLE 1"]
src_paths = ["src"]


# RUFF
[tool.ruff]
line-length = 120
indent-width = 4
target-version = "py312"
src = [".", "src"]

[tool.ruff.lint]
select = [
  # https://docs.astral.sh/ruff/rules/
  "F",    # Pyflakes
  "E",    # pycodestyle Error
  "W",    # pycodestyle Warning
  "I",    # sort
  "N",    # pep8-naming
  "UP",   # pyupgrade
  "ANN",  # flake8-annotations
  "B",    # flake8-bugbear
  "A",    # flake8-builtins
  "C4",   # flake8-comprehensions
  "DTZ",  # flake8-datetimez
  "T10",  # flake8-debugger
  "LOG",  # flake8-logging
  "PIE",  # flake8-pie
  "PT",   # flake8-pytest-style
  "RET",  # flake8-return
  "SIM",  # flake8-simplify
  "ARG",  # flake8-unused-arguments
  # "PTH",  # flake8-use-pathlib
  "TD",   # flake8-todos
  "PERF", # Perflint
  "FURB", # refurb
  "RUF",  # Ruff-specific rules
]
ignore = [
  "N812", # Lowercase `functions` imported as non-lowercase `F`
  "ANN204", # Missing return type annotation for special method
]

[tool.ruff.lint.isort]
case-sensitive = true
lines-after-imports = 2

[tool.ruff.format]
indent-style = "space"
line-ending = "lf"
quote-style = "double"

[tool.ruff.lint.flake8-annotations]
mypy-init-return = true


# # PYLINT
# [tool.pylint.main]
# py-version = "3.11"
# source-roots = ["."]
# load-plugins = [
#     "pylint.extensions.bad_builtin",
#     "pylint.extensions.check_elif",
#     "pylint.extensions.comparison_placement",
#     "pylint.extensions.dict_init_mutate",
#     "pylint.extensions.docstyle",
#     "pylint.extensions.empty_comment",
#     "pylint.extensions.for_any_all",
#     "pylint.extensions.mccabe",
#     "pylint.extensions.no_self_use",
#     "pylint.extensions.private_import",
#     "pylint.extensions.redefined_loop_name",
#     "pylint.extensions.redefined_variable_type",
#     "pylint.extensions.typing",
# ]

# [tool.pylint.logging]
# logging-format-style = "new"

# [tool.pylint.format]
# max-line-length = 120
# expected-line-ending-format = "LF"

# [tool.pylint.messages_control]
# disable = """
#     wrong-import-position,
#     import-outside-toplevel,
#     docstring-first-line-empty,
#     fixme,
#     no-name-in-module,
#     too-few-public-methods,
#     logging-fstring-interpolation,
#     too-many-instance-attributes,
# """
# # missing-class-docstring,
# # missing-module-docstring,
# # duplicate-code,

# PYTEST
[tool.pytest.ini_options]
pythonpath = ["."]
spark_options = ["spark.sql.session.timeZone: UTC"]

# POETRY
[tool.poetry]
package-mode = false  # use only for dependency management
name = "databricks_pipelines"

# VERSIONS
[tool.poetry.dependencies]
python = "3.12.*"  # Python 3.12 is used for Databricks runtime 16.1 https://docs.databricks.com/en/release-notes/runtime/index.html
databricks-sdk = "*"
python-dotenv = "*"

[tool.poetry.group.dev.dependencies]
pyspark = "3.5.*"
delta-spark = "3.3.*"  # Spark compatibility: https://docs.delta.io/latest/releases.html#compatibility-with-apache-spark
databricks-dlt = "*"  # Python stub for Delta Live Tables
# linters
# pylint = "*"
# mypy = "*"
black = "*"
ruff = "*"
isort = "*"
# testing
pytest = "*"
pytest-spark = "*"
# other
colorama = "*"
